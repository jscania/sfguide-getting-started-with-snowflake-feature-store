{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Version: 0.0.2  Updated date: 07/05/2024\n",
    "Conda Environment : py-snowpark_df_ml_fs-1.15.0_v1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Snowflake Feature Store - Â Customer Segmentation\n",
    "\n",
    "## Setup Database Environment\n",
    "\n",
    "This Notebook is used to setup the required database objects including the source data for this use-case.\n",
    "\n",
    "We will create :\n",
    "- a database that will store all our database artifacts and raw source data\n",
    "- a database that will be setup to simulate ingesting of raw source data in an incrementing fashion\n",
    "- schemas to simulate different environments for development (TRAINING*) and production (SERVING*)\n",
    "- a data-scientist role that will have permissions to \n",
    "    - develop features and train models in our development schemas\n",
    "    - productionize our feature-engineering and ML pipeline in the production schemas\n",
    "\n",
    "In a 'live' environment you may have several roles with different permissions over Development and Production that are used to maintain separation of concerns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Install SQLGlot** <br>\n",
    "Install SQLGlot with pip install in the conda environment **py-snowpark_df_ml_fs** by running the following command in the same terminal window.  We will use this package to format the SQL produced from Snowpark so that it is human-readable in the Dynamic Tables that Feature Store creates.  Installing within the Notebook, as other users have reported issues trying to install directly within the OS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sqlglot[rs] in /opt/conda/envs/snowflake-demo/lib/python3.10/site-packages (26.3.6)\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install \"sqlglot[rs]\" --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notebook Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Python packages\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "# SNOWFLAKE\n",
    "# Snowpark\n",
    "from snowflake.snowpark import Session, DataFrame, Window, WindowSpec\n",
    "import snowflake.snowpark.functions as F\n",
    "import snowflake.snowpark.types as T\n",
    "from snowflake.snowpark.version import VERSION\n",
    "from snowflake.ml.utils import connection_params\n",
    "\n",
    "from useful_fns import run_sql"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Snowflake connection and database parameters\n",
    "\n",
    "Change the settings below if you want to if need to apply to your Snowflake Account.\n",
    "\n",
    "E.g. if you need to use a different role with ACCOUNTADMIN privileges to setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# Roles\n",
    "aa_role = 'ACCOUNTADMIN'        # Either a ACCOUNTADMIN, or another role that has been granted ACCOUNTADMIN privileges\n",
    "fs_qs_role = 'FS_QS_ROLE'       # The Data-Scientist role that will create an have permissions over the data, Feature-Store and Model-Registry\n",
    "\n",
    "# Database\n",
    "scale_factor               = 'SF0001'  # TPCXAI data comes in a number of Scale Factors.  For this quickstart we are using the lowest Scale Factor\n",
    "tpcxai_database_base       = f'TPCXAI_{scale_factor}_QUICKSTART' # The Database we will create to contain the base static data\n",
    "tpcxai_database_inc        = f'{tpcxai_database_base}_INC' # The Database we will create to contain the pseudo 'Live' incrementing data\n",
    "databases = [tpcxai_database_base,tpcxai_database_inc]\n",
    "\n",
    "# Schemas\n",
    "tpcxai_config_schema       = 'CONFIG'   # This Config Schema containing database artifacts to manage the Quickstart databases\n",
    "tpcxai_training_schema     = 'TRAINING' # The Training (Development) schema\n",
    "tpcxai_scoring_schema      = 'SCORING'  # The Scoring (Test) schema\n",
    "tpcxai_serving_schema      = 'SERVING'  # The Serving (Production) schema\n",
    "schemas = [tpcxai_training_schema, tpcxai_scoring_schema, tpcxai_serving_schema,]\n",
    "fq_schemas = []\n",
    "for d in databases:\n",
    "    for s in schemas:\n",
    "        fq_schemas.append(f'''{d}.{s}''')        \n",
    "\n",
    "# S3 bucket - public access bucket containing source data files\n",
    "s3_bucket = f's3://sfquickstarts/getting_started_with_snowflake_feature_store/'\n",
    "# Stage\n",
    "tpcxai_internal_stage = 'TPCXAI_STAGE'  # The Stage name we will use to represent the S3 bucket\n",
    "\n",
    "# Warehouse\n",
    "tpcxai_warehouse = f'TPCXAI_{scale_factor}_QUICKSTART_WH'  # The name of the Warehouse we will use for any Quickstart processing\n",
    "initial_wh_size = 'XSMALL' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Snowflake Session object\n",
    "connection_parameters = connection_params.SnowflakeLoginOptions(\"lk16562\")\n",
    "session = Session.builder.configs(connection_parameters).create()\n",
    "session.sql_simplifier_enabled = True\n",
    "snowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\n",
    "snowpark_version = VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current Environment Details\n",
    "print('\\nConnection Established with the following parameters:')\n",
    "print(f'User                        : {snowflake_environment[0][0]}')\n",
    "print(f'Role                        : {session.get_current_role()}')\n",
    "print(f'Database                    : {session.get_current_database()}')\n",
    "print(f'Schema                      : {session.get_current_schema()}')\n",
    "print(f'Warehouse                   : {session.get_current_warehouse()}')\n",
    "print(f'Snowflake version           : {snowflake_environment[0][1]}')\n",
    "print(f'Snowpark for Python version : {snowpark_version[0]}.{snowpark_version[1]}.{snowpark_version[2]} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {aa_role}''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup master role and permissions\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "# Role\n",
    "run_sql(f'''create role if not exists {fs_qs_role}''', session)\n",
    "run_sql(f'''grant role {fs_qs_role} to role SYSADMIN''', session)\n",
    "\n",
    "# Warehouse\n",
    "run_sql(f'''create warehouse if not exists {tpcxai_warehouse}  warehouse_size = {initial_wh_size}''', session)\n",
    "run_sql(f'''grant all on warehouse {tpcxai_warehouse} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''use warehouse {tpcxai_warehouse}''', session)\n",
    "\n",
    "# Tasks\n",
    "run_sql(f'''grant execute managed task on account to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant execute task on account to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Database -  BASE\n",
    "run_sql(f'''use role {aa_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_base}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_base} to role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create database if not exists {tpcxai_database_inc}''', session)\n",
    "run_sql(f'''grant all on database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on all schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant all on future schemas in database {tpcxai_database_inc} to role {fs_qs_role}''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objects in BASE database\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_training_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_serving_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_scoring_schema}''', session)\n",
    "\n",
    "run_sql(f'''create schema  if not exists {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "run_sql(f'''use schema {tpcxai_database_base}.{tpcxai_config_schema}''', session)\n",
    "\n",
    "run_sql(f'''create file format if not exists {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff type = 'parquet' ''', session)\n",
    "\n",
    "run_sql(f'''create stage if not exists {tpcxai_database_base}.{tpcxai_config_schema}.{tpcxai_internal_stage} \n",
    "        file_format = {tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff \n",
    "        url = '{s3_bucket}' ''', session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "\n",
    "# Calculate the DATE point difference between the source data and todays date.  \n",
    "# This reference point will be used to select a subset of the data for pre-loading, and the remainder will be incrementally ingested via a scheduled task.\n",
    "date_diff_to_source = session.sql('''select timestampdiff('days',  '2013-04-01', CURRENT_DATE() )::VARCHAR date_diff_to_source''').collect()[0][0]\n",
    "print('Difference in Days between source data and current date :',date_diff_to_source)\n",
    "\n",
    "##Â STATIC DATABASE SETUP - TPCXAI_SF001_QUICKSTART\n",
    "\n",
    "# Iteration over the Schemas creating and loading the required tables in each\n",
    "for s in [tpcxai_training_schema, tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    # CUSTOMER\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.CUSTOMER \n",
    "            FROM \n",
    "                 (select $1:C_CUSTOMER_SK::INTEGER,\n",
    "                         $1:C_CUSTOMER_ID::VARCHAR,\n",
    "                         $1:C_CURRENT_ADDR_SK::INTEGER,\n",
    "                         $1:C_FIRST_NAME::VARCHAR,\n",
    "                         $1:C_LAST_NAME::VARCHAR,\n",
    "                         $1:C_PREFERRED_CUST_FLAG::VARCHAR,\n",
    "                         $1:C_BIRTH_DAY::INTEGER,\n",
    "                         $1:C_BIRTH_MONTH::INTEGER,\n",
    "                         $1:C_BIRTH_YEAR::INTEGER,\n",
    "                         $1:C_BIRTH_COUNTRY::VARCHAR,\n",
    "                         $1:C_LOGIN::VARCHAR,\n",
    "                         $1:C_EMAIL_ADDRESS::VARCHAR,                        \n",
    "                         $1:C_CLUSTER_ID::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/CUSTOMER) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDERS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_DATE)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDERS \n",
    "            FROM \n",
    "                 (select $1:O_ORDER_ID::INTEGER,\n",
    "                         $1:O_CUSTOMER_SK::INTEGER,\n",
    "                         timestampadd('MINS', UNIFORM( -1440 , 0 , random() ) ,timestampadd('days',   {date_diff_to_source}, $1:\"DATE\"::DATE)) ORDER_TS,\n",
    "                         decode(extract(dayofweek from ORDER_TS), 1, 'Monday', 2, 'Tuesday', 3, 'Wednesday', 4, 'Thursday',  5, 'Friday',  6, 'Saturday',  0, 'Sunday') WEEKDAY,\n",
    "                         TO_DATE(ORDER_TS) ORDER_DATE,\n",
    "                         $1:STORE::INTEGER,\n",
    "                         $1:TRIP_TYPE::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDERS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # LINEITEM\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.LINEITEM \n",
    "            FROM (select $1:LI_ORDER_ID::INTEGER,\n",
    "                         $1:LI_PRODUCT_ID::INTEGER,\n",
    "                         $1:QUANTITY::INTEGER,\n",
    "                         $1:PRICE::DECIMAL(8,2)\n",
    "                  from @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/LINEITEM) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "    # ORDER_RETURNS\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_base}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID);\n",
    "    ''', session)\n",
    "    run_sql(f'''COPY INTO {tpcxai_database_base}.{s}.ORDER_RETURNS \n",
    "            FROM (select $1:OR_ORDER_ID::INTEGER,\n",
    "                         $1:OR_PRODUCT_ID::INTEGER,\n",
    "                         $1:OR_RETURN_QUANTITY::INTEGER\n",
    "                  from  @{tpcxai_database_base}.CONFIG.{tpcxai_internal_stage}/{s}/ORDER_RETURNS) \n",
    "            FILE_FORMAT = (FORMAT_NAME = '{tpcxai_database_base}.{tpcxai_config_schema}.parquet_ff' ) ''', session) \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â INCREMENTAL DATABASE SETUP - TPCXAI_SF001_QUICKSTART_INC\n",
    "\n",
    "# Training schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_training_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_training_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "# run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_training_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Serving schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_serving_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_serving_schema} to role {fs_qs_role}''')\n",
    "\n",
    "# Scoring schema\n",
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "run_sql(f'''create schema if not exists {tpcxai_database_inc}.{tpcxai_scoring_schema}''', session)\n",
    "run_sql(f'''grant usage on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create view on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create tag on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant create dataset on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,references on all views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,references on future views in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant create dynamic table on schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "run_sql(f'''grant select,monitor on all dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant select,monitor on future dynamic tables in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n",
    "run_sql(f'''grant usage on all datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''', session)\n",
    "#run_sql(f'''grant usage on future datasets in schema {tpcxai_database_inc}.{tpcxai_scoring_schema} to role {fs_qs_role}''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {aa_role}''', session)\n",
    "for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "    run_sql(f'''drop table {tpcxai_database_inc}.{s}.CUSTOMER''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_sql(f'''use role {fs_qs_role}''', session)\n",
    "# Set up Incremental SERVING & SCORING data maintenance\n",
    "for s in [tpcxai_serving_schema, tpcxai_scoring_schema]:\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.CUSTOMER\n",
    "                  (C_CUSTOMER_SK INTEGER,\n",
    "                   C_CUSTOMER_ID VARCHAR,\n",
    "                   C_CURRENT_ADDR_SK INTEGER,\n",
    "                   C_FIRST_NAME VARCHAR,\n",
    "                   C_LAST_NAME VARCHAR,\n",
    "                   C_PREFERRED_CUST_FLAG VARCHAR,\n",
    "                   C_BIRTH_DAY INTEGER,\n",
    "                   C_BIRTH_MONTH INTEGER,\n",
    "                   C_BIRTH_YEAR INTEGER,\n",
    "                   C_BIRTH_COUNTRY VARCHAR,\n",
    "                   C_LOGIN VARCHAR,\n",
    "                   C_EMAIL_ADDRESS VARCHAR,\n",
    "                   C_CLUSTER_ID INTEGER\n",
    "                  ) CLUSTER BY (C_CUSTOMER_SK)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''insert into {tpcxai_database_inc}.{s}.CUSTOMER select * from {tpcxai_database_base}.{s}.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "    \n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDERS\n",
    "    (O_ORDER_ID INTEGER,\n",
    "     O_CUSTOMER_SK INTEGER,\n",
    "     ORDER_TS TIMESTAMP,\n",
    "     WEEKDAY VARCHAR,\n",
    "     ORDER_DATE DATE,\n",
    "     STORE INTEGER,\n",
    "     TRIP_TYPE INTEGER)\n",
    "     CLUSTER BY (O_ORDER_ID, ORDER_TS)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.LINEITEM\n",
    "    (LI_ORDER_ID INTEGER,\n",
    "     LI_PRODUCT_ID INTEGER,\n",
    "     QUANTITY INTEGER,\n",
    "     PRICE DECIMAL(8,2))\n",
    "    CLUSTER BY (LI_PRODUCT_ID, LI_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    run_sql(f'''CREATE OR REPLACE TABLE {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "    (OR_ORDER_ID INTEGER,\n",
    "     OR_PRODUCT_ID INTEGER,\n",
    "     OR_RETURN_QUANTITY INTEGER)\n",
    "     CLUSTER BY (OR_PRODUCT_ID, OR_ORDER_ID)\n",
    "    ''', session)\n",
    "\n",
    "    # Streams\n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "    run_sql(f''' create or replace stream {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM on table {tpcxai_database_inc}.{s}.ORDERS''', session) \n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK\n",
    "    schedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.LINEITEM\n",
    "select l.* \n",
    "from  {tpcxai_database_base}.{s}.LINEITEM l,\n",
    "      {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_LINEITEM_STREAM o\n",
    "where l.LI_ORDER_ID = o.O_ORDER_ID\n",
    "order by LI_ORDER_ID, LI_PRODUCT_ID''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_LINEITEM_TASK resume''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\twhen SYSTEM$STREAM_HAS_DATA('{tpcxai_database_base}.CONFIG.{s}_ORDER_ORDERRETURNS_STREAM')\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDER_RETURNS\n",
    "select o_r.* \n",
    "from {tpcxai_database_base}.{s}.ORDER_RETURNS o_r,\n",
    "     {tpcxai_database_base}.{tpcxai_config_schema}.{s}_ORDER_ORDERRETURNS_STREAM o\n",
    "where o_r.OR_ORDER_ID = o.O_ORDER_ID\n",
    "order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_RETURNS_TASK resume ''', session)\n",
    "\n",
    "    run_sql(f''' insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "select * from {tpcxai_database_base}.{s}.ORDERS o\n",
    "where o.ORDER_TS < current_timestamp() \n",
    "order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' create or replace task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK\n",
    "\tschedule='1 MINUTE'\n",
    "\tUSER_TASK_MANAGED_INITIAL_WAREHOUSE_SIZE='XSMALL'\n",
    "\tas insert into {tpcxai_database_inc}.{s}.ORDERS\n",
    "with o_max_timestamp as ( select max(ORDER_TS) max_ts\n",
    "                           from {tpcxai_database_inc}.{s}.ORDERS )\n",
    "     select O_ORDER_ID, O_CUSTOMER_SK, ORDER_TS, WEEKDAY, ORDER_DATE, STORE, TRIP_TYPE\n",
    "       from {tpcxai_database_base}.{s}.ORDERS o,\n",
    "            o_max_timestamp fmt\n",
    "      where \n",
    "            o.ORDER_TS <= current_timestamp() \n",
    "        and o.ORDER_TS > fmt.max_ts\n",
    "   order by ORDER_TS, O_CUSTOMER_SK ''', session)\n",
    "\n",
    "    run_sql(f''' alter task {tpcxai_database_base}.{tpcxai_config_schema}.APPEND_{s}_ORDER_TASK resume ''', session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up incremental database TRAINING schema that holds static, rather than incrementing database\n",
    "\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.CUSTOMER      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.CUSTOMER order by C_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.LINEITEM      as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.LINEITEM order by LI_ORDER_ID ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDERS        as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDERS order by ORDER_TS, O_ORDER_ID, O_CUSTOMER_SK ''', session)\n",
    "run_sql(f''' create table TPCXAI_SF0001_QUICKSTART_INC.TRAINING.ORDER_RETURNS as select * from TPCXAI_SF0001_QUICKSTART.TRAINING.ORDER_RETURNS order by OR_ORDER_ID, OR_PRODUCT_ID ''', session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLEAN UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snowflake-demo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
